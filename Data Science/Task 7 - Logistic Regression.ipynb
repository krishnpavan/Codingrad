{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9d8f6598",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29da02b5",
   "metadata": {},
   "source": [
    "<img src= \"https://i.pinimg.com/736x/53/44/a1/5344a1f885466272b8d0be85df922006.jpg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16b50b1",
   "metadata": {},
   "source": [
    "* Logistic Regression is one of the most popular Machine Learning algorithms which comes under Supervised Learning technique, it is used for predicting the categorical dependent variable using a given set of independent variables\n",
    "\n",
    "* Logistic Regression is much similar to Linear Regression except that how they are used. Linear regression is used for solving regression problems, whereas Logisticregression is used for solving classification problems\n",
    "\n",
    "* In Logistic regression instead of fitting regression line, we fit an \"S\" shaped logistic function which two maximum values (0 or 1)\n",
    "\n",
    "* Logistic Regression is a significant machine learning algorithm because it has the ability to provide probabilities and classify new data using continuous and discrete datasets\n",
    "\n",
    "* Logistc Regression can be used to classify the observation using different types of data and can easily determine the most effective variables used for the classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635c8d4",
   "metadata": {},
   "source": [
    "## Logistic Function (Sigmoid Function):\n",
    "\n",
    "* Sigmoid function is the mathematical function used to map the predicted values to probabilities\n",
    "* It maps any real value into another value with in a range of 0 and 1\n",
    "* The value of Logistic Regression must be between 0 and 1, which cannot go beyond this limit, so it forms a curve like the 'S' form. The S-from curve is called the Sigmoid function or Logistic function\n",
    "* In logistic regression, concept of threshold value is used, which defines the probability of either 0 or 1.Such as values above the threshold value tends to 1, and value below threshold tends to 0.\n",
    "\n",
    "## Sigmoid function formula\n",
    "\n",
    "$$y_{pred} =\\frac{1}{1 + e^{-xcap}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1842b8",
   "metadata": {},
   "source": [
    "## Logistic Regression requirements\n",
    "\n",
    "* The dependent variable must be categorical in nature\n",
    "* The independent variable should not have multi-colinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34696c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dac8e737",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {\n",
    "    \"X\" : [0.1, 0.2, 0.3, 0.4, 0.6, 0.7, 0.8, 0.9],\n",
    "    \"Y\" : [0, 0, 0, 0, 1, 1, 1, 1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "08497fb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=b5641ac0-a640-4a36-b7ec-fb534a548bc6 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('b5641ac0-a640-4a36-b7ec-fb534a548bc6').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "     X  Y\n",
       "0  0.1  0\n",
       "1  0.2  0\n",
       "2  0.3  0\n",
       "3  0.4  0\n",
       "4  0.6  1\n",
       "5  0.7  1\n",
       "6  0.8  1\n",
       "7  0.9  1"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b73019d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.0\n",
       "1    0.0\n",
       "2    0.0\n",
       "3    0.0\n",
       "4    0.6\n",
       "5    0.7\n",
       "6    0.8\n",
       "7    0.9\n",
       "Name: SumX_Y, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding multiplication of X and Y\n",
    "df['SumX_Y'] = df['X'] * df['Y']\n",
    "df['SumX_Y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b7233b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.01\n",
       "1    0.04\n",
       "2    0.09\n",
       "3    0.16\n",
       "4    0.36\n",
       "5    0.49\n",
       "6    0.64\n",
       "7    0.81\n",
       "Name: Sqr_X, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding square of X\n",
    "df['Sqr_X'] = df['X'] ** 2\n",
    "df['Sqr_X']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32773fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><div id=2003a3ca-b522-44e5-baf8-17ca372aa7c1 style=\"display:none; background-color:#9D6CFF; color:white; width:200px; height:30px; padding-left:5px; border-radius:4px; flex-direction:row; justify-content:space-around; align-items:center;\" onmouseover=\"this.style.backgroundColor='#BA9BF8'\" onmouseout=\"this.style.backgroundColor='#9D6CFF'\" onclick=\"window.commands?.execute('create-mitosheet-from-dataframe-output');\">See Full Dataframe in Mito</div> <script> if (window.commands.hasCommand('create-mitosheet-from-dataframe-output')) document.getElementById('2003a3ca-b522-44e5-baf8-17ca372aa7c1').style.display = 'flex' </script> <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>SumX_Y</th>\n",
       "      <th>Sqr_X</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.6</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.7</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.9</td>\n",
       "      <td>1</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table></div>"
      ],
      "text/plain": [
       "     X  Y  SumX_Y  Sqr_X\n",
       "0  0.1  0     0.0   0.01\n",
       "1  0.2  0     0.0   0.04\n",
       "2  0.3  0     0.0   0.09\n",
       "3  0.4  0     0.0   0.16\n",
       "4  0.6  1     0.6   0.36\n",
       "5  0.7  1     0.7   0.49\n",
       "6  0.8  1     0.8   0.64\n",
       "7  0.9  1     0.9   0.81"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eed9faa5",
   "metadata": {},
   "source": [
    "## Sigmoid function formula\n",
    "\n",
    "$$y_{pred} =\\frac{1}{1 + e^{-xcap}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b9df74",
   "metadata": {},
   "source": [
    "## Confusion Matrix: -\n",
    "* A confusion matrix is a table this is often used to describe the performance of a classification model on a set of test data for which the true values are known.\n",
    "* The Confuson Matrix shows the ways in which your classiication model is confused when it makes predictions.\n",
    "\n",
    "## True Positive (TP) = For correctly predicted event values\n",
    "## False Positive (FP)  = For incorrectly predicted event values\n",
    "## True Negative (TN) = For correctly predicted no-event values\n",
    "## False Neagative (FN) = For incorrectly predicted no-event values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "474b6b01",
   "metadata": {},
   "source": [
    "## Evaluating Logistc Regression using Accuracy, Precision, Recall and F1 Score\n",
    "\n",
    "<img src = \"https://www.researchgate.net/publication/346062755/figure/fig5/AS:960496597483542@1606011642491/Confusion-matrix-and-performance-evaluation-metrics.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73cf905",
   "metadata": {},
   "source": [
    "## Accuracy :-\n",
    "\n",
    "* It is used to check the accuracy of the predicted data. \n",
    "* In total no of predicted values how much percentage of the data is accurately predicted is known as accuracy.\n",
    "* Accuracy greater than 70% is a great model performance.\n",
    "* In fact, an accuracy measure of anything between 70%-90% is not only ideal, it's realistic. This is also consistent with industry standards.\n",
    "* Accuracy formula is shown as below\n",
    "              \n",
    "$$Accuracy = (\\frac{Total No.of Correctly Predicted values}{Total no.of values}) * 100$$\n",
    "\n",
    "OR\n",
    "\n",
    "$$Accuracy = \\frac{(TP + TN)}{(TP + TN + FP + FN)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5822640c",
   "metadata": {},
   "source": [
    "# Precision :-\n",
    " \n",
    "* Precision is the fraction of relevant instances among the retrieved instances. \n",
    "* Precision is always calculated based on predicted values only.\n",
    "* Precision can be seen as a measure of quality\n",
    "* The precision value lies between 0 and 1. \n",
    "* Higher precision i.e. nearer to 1 means that an algorithm returns more relevant results than irrelevant ones,\n",
    "* Precision is more important than recall when you would like to have less False Positives in trade off to have more False Negatives. Meaning, getting a False Positive is very costly, and a False Negative is not as much.\n",
    "\n",
    "              \n",
    "$$Precision = \\frac{True Positives}{Selected Elements}$$\n",
    "\n",
    "OR\n",
    "\n",
    "$$Precision = \\frac{TP}{(TP + FP)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "007b6eb7",
   "metadata": {},
   "source": [
    "# Recall :-\n",
    "\n",
    "* Recall is the fraction of relevant instances that were retrieved. \n",
    "* Recall is always calculated based on original values only.\n",
    "* Recall is more important where Overlooked Cases (False Negatives) are more costly than False Alarms (False Positive). The focus in these problems is finding the positive cases.\n",
    "* Recall should be near to 1 (high) for a good classifier\n",
    "              \n",
    "$$Recall = \\frac{True Positives}{Relevant Elements}$$\n",
    "\n",
    "OR\n",
    "\n",
    "$$Recall = \\frac{TP}{(TP + FN)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1e9bb9d",
   "metadata": {},
   "source": [
    "## F1 Score :-\n",
    "\n",
    "* F1 Score is the harmonic mean of precision and recall. \n",
    "* In the most simple terms, higher F1 scores are generally better. \n",
    "* F1 scores can range from 0 to 1, with 1 representing a model that perfectly classifies each observation into the correct class and 0 representing a model that is unable to classify any observation into the correct class.\n",
    "* Formula for F1 score is shown below. P is Precision value and R is Recall value\n",
    "\n",
    "\n",
    "$$f1 = 2\\tfrac{P*R}{P+R}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2bff2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class logistic_Regression:\n",
    "        def __init__(self, df):\n",
    "            self.sum_xy = df['SumX_Y'].sum()\n",
    "            self.sum_x = df['X'].sum()\n",
    "            self.sum_y = df['Y'].sum()\n",
    "            self.sqr_x = df['Sqr_X'].sum()\n",
    "            self.sumX_h_2 = self.sum_x ** 2 \n",
    "            self.n = len(df)\n",
    "        \n",
    "        def M(self, sum_xy, sum_x, sum_y, sqr_x, sumX_h_2, n):   # To find m value\n",
    "            self.numerator = n*((sum_xy)) - (sum_x) * (sum_y)\n",
    "            self.denominator = n*((sqr_x)) - (sumX_h_2)\n",
    "            m = numerator / denominator\n",
    "            return m\n",
    "            \n",
    "        def B(self, n, sum_x, sum_y):                                            # TO find b value\n",
    "            self.numerator_b = ((sum_y) - (m * sum_x))\n",
    "            self.denominator_b = n\n",
    "            self.b = self.numerator_b / self.denominator_b\n",
    "            return self.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aab0a8b8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sum_xy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4f03117c7be6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# object.methodname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mm_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_xy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msumX_h_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# printing the b value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sum_xy' is not defined"
     ]
    }
   ],
   "source": [
    "# object declaration for b(constant)\n",
    "m_obj = logistic_Regression(df)\n",
    "\n",
    "# object.methodname\n",
    "m_obj.M(sum_xy, sum_x, sum_y, sqr_x, sumX_h_2, n)\n",
    "\n",
    "# printing the b value\n",
    "print(\"m value is: \", M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a601fa6b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9b4b5e2f971c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Calculating Accuracy, Precision, Recall and F1 Score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mlogistic_Regression\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum_xy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'SumX_Y'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-9b4b5e2f971c>\u001b[0m in \u001b[0;36mlogistic_Regression\u001b[1;34m()\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mX_cap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_cap value is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-9b4b5e2f971c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0mX_cap\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mX\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'X'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"X_cap value is: \"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_cap\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'm' is not defined"
     ]
    }
   ],
   "source": [
    "# Calculating Accuracy, Precision, Recall and F1 Score\n",
    "\n",
    "class logistic_Regression:\n",
    "        def __init__(self, df):\n",
    "            self.sum_xy = df['SumX_Y'].sum()\n",
    "            self.sum_x = df['X'].sum()\n",
    "            self.sum_y = df['Y'].sum()\n",
    "            self.sqr_x = df['Sqr_X'].sum()\n",
    "            self.sumX_h_2 = self.sum_x ** 2 \n",
    "            self.n = len(df)\n",
    "        \n",
    "        def M(self, sum_xy, sum_x, sum_y, sqr_x, sumX_h_2, n):   # To find m value\n",
    "            self.numerator = n*((sum_xy)) - (sum_x) * (sum_y)\n",
    "            self.denominator = n*((sqr_x)) - (sumX_h_2)\n",
    "            m = numerator / denominator\n",
    "            return m\n",
    "            \n",
    "        def B(self, n, sum_x, sum_y):                                            # TO find b value\n",
    "            self.numerator_b = ((sum_y) - (m * sum_x))\n",
    "            self.denominator_b = n\n",
    "            self.b = self.numerator_b / self.denominator_b\n",
    "            return self.b\n",
    "        \n",
    "        X_cap = [(m*X + b) for X in df['X']]\n",
    "        print(\"X_cap value is: \", X_cap)   \n",
    "\n",
    "    \n",
    "        def sigmoid(X_cap):       ## To find sigmoid of X_cap for finding ypred\n",
    "            return [(1 / (1 + np.exp(-xcap))) for xcap in X_cap]\n",
    "        \n",
    "        ypred = sigmoid(X_cap)                                    # Finding Ypred \n",
    "        print(\"Sigmoid values:\",ypred)\n",
    "    \n",
    "        def final(ypred):    # replacing values in ypred with 0 and 1 \n",
    "            re = [1 if val >= 0.5 else 0 for val in ypred]\n",
    "            return re\n",
    "    \n",
    "        ypred = final(ypred)                                     # y-prediction values\n",
    "        print(\"y predicted values: \", ypred)\n",
    "            \n",
    "        ytrue = df.Y.values                                      # y-original values\n",
    "        print(\"y true values: \", ytrue)\n",
    "    \n",
    "        def conf_matrix(self,ypred,ytrue):  # Confusion matrix\n",
    "            TP = 0           # Initializing True Positive (TP), Flase Positive (FP), True Negative (TN), False Negative (FN) values to 0\n",
    "            FP = 0\n",
    "            TN = 0\n",
    "            FN = 0\n",
    "        \n",
    "            for i in range(len(ypred)):\n",
    "                if ytrue[i]==ypred[i]==1:\n",
    "                    TP +=1\n",
    "                if ypred[i]==1 and ytrue[i]!=ypred[i]:\n",
    "                    FP +=1\n",
    "                if ytrue[i]==ypred[i]==0:\n",
    "                    TN +=1\n",
    "                if ypred[i]==0 and ytrue[i]!=ypred[i]:\n",
    "                    FN +=1\n",
    "                \n",
    "            return TP,FP,TN,FN\n",
    "        #print(\"Confusion matrix: \",conf_matrix(ytrue,ypred))\n",
    "    \n",
    "        def evaluate_1(self, TP,FP,TN,FN):    # Evaluating for correct values i.e. For 1 (Predicted values are close or same)\n",
    "            accuracy_1 = (TP + TN)/(TP + FP + FN + TN)  # for 1 (Predicted values are close or same)\n",
    "            precision_1 = (TP)/(TP + FP)\n",
    "            recall_1 = (TP)/(TP + FN)\n",
    "            f1_score_1 = 2 * ((precision_1 * recall_1)/(precision_1 + recall_1))\n",
    "            return accuracy_1, precision_1, recall_1, f1_score_1\n",
    "    \n",
    "        def evaluate_0(self, TP,FP,TN,FN):    # Evaluating for incorrect values i.e. For 0 (Predicted values are not close or not same)\n",
    "            accuracy_0 = (TP + TN)/(TP + FP + FN + TN)  # for 0 (Predicted values are not close or not same)\n",
    "            precision_0 = (TN)/(FN + TN)\n",
    "            recall_0 = (TN)/(FP + TN)\n",
    "            f1_score_0 = 2 * ((precision_) * recall_0/(precision_0 + recall_0))\n",
    "            return accuracy_0, precision_0, recall_0, f1_score_0\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8443e33c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sum_xy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-4f03117c7be6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# object.methodname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mm_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum_xy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msum_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msqr_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msumX_h_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# printing the b value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sum_xy' is not defined"
     ]
    }
   ],
   "source": [
    "# object declaration for b(constant)\n",
    "m_obj = logistic_Regression(df)\n",
    "\n",
    "# object.methodname\n",
    "m_obj.M(sum_xy, sum_x, sum_y, sqr_x, sumX_h_2, n)\n",
    "\n",
    "# printing the b value\n",
    "print(\"m value is: \", M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b732f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae4356",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
